---
title: "Predicción de ingresos"
author: "Eduardo Chamizo"
date: "2025-06-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Resumen

Este proyecto desarrolla un modelo predictivo para clasificar si una persona 
gana más de $50,000 al año basándose en características demográficas y laborales
del Census Income Dataset (Adult). Utilizamos XGBoost, un algoritmo de gradient
boosting, alcanzando una precisión del 82% en el conjunto de prueba.

## Objetivo del problema

Predecir si el ingreso anual de una persona supera los $50,000.

-Segmentación de mercado para productos financieros
-Políticas públicas de asistencia social
-Análisis de equidad salarial

# Instalar y cargar librerías necesarias

```{r,message=FALSE,warning=FALSE}
library(OpenML)
library(xgboost)
library(dplyr)
```

# Descargar el dataset "adult" de OpenML (ID = 1590)

```{r,message=FALSE,warning=FALSE}
adult_data <- getOMLDataSet(data.id = 1590)
adult <- adult_data$data
```

# Preprocesamiento básico
## Convertir target y quitar columnas con 0 en la mayoría de entradas
```{r,results='hide'}
adult$class <- ifelse(adult$class == ">50K", 1, 0)
sapply(adult, unique)
```
###Las variables "fnlwgt", "capital.gain", "capital.loss" se quitarán; la de nacionalidad, se reajustará como procede:

```{r}
sort(table(adult$native.country))
adult$native.country<-ifelse(adult$native.country=="United-States","United States","Rest of the world")
adult<-adult[,c(-3,-11,-12)]
```
## Convertir el conjunto de variables explicativas en matriz

```{r}
adultmatrix <- as.matrix(adult[,-12])
adultclass<-adult$class
```

## Partición train-test

```{r}
set.seed(123)
n = nrow(adult)
ind = sample(n,n*2/3)
train.adultmatrix = adultmatrix[ind,]
train.adultclass = adultclass[ind]
test.adultmatrix = adultmatrix[-ind,]
test.adultclass = adultclass[-ind]
nrow(train.adultmatrix)==length(train.adultclass)
```

## Limpiar datos

```{r}
train_data <- adultmatrix[ind, ]
train.adultclass <- adultclass[ind]
complete_rows <- complete.cases(train_data)
train_data_clean <- train_data[complete_rows, ]
train.adultclass <- train.adultclass[complete_rows]

test_data <- adultmatrix[-ind, ]
test.adultclass <- adultclass[-ind]
complete_rows_test <- complete.cases(test_data)
test_data_clean <- test_data[complete_rows_test, ]
test.adultclass <- test.adultclass[complete_rows_test]
```

## Transformar de tabla de datos a matrices

```{r}
train.adultmatrix <- model.matrix(~ . - 1, data = as.data.frame(train_data_clean))
test.adultmatrix <- model.matrix(~ . - 1, data = as.data.frame(test_data_clean))
```

## Limpiar etiquetas de entrenamiento y de prueba

```{r}
sum(is.na(train.adultclass))
sum(is.infinite(train.adultclass))

valid_labels <- !is.na(train.adultclass) & 
               !is.infinite(train.adultclass) & 
               train.adultclass %in% c(0, 1)
train.adultmatrix <- train.adultmatrix[valid_labels, ]
train.adultclass <- train.adultclass[valid_labels]

valid_labels_test <- !is.na(test.adultclass) & 
                    !is.infinite(test.adultclass) & 
                    test.adultclass %in% c(0, 1)
test.adultmatrix <- test.adultmatrix[valid_labels_test, ]
test.adultclass <- test.adultclass[valid_labels_test]
```

## Convertir etiquetas a numérico

```{r}
train.adultclass <- as.numeric(train.adultclass)
test.adultclass <- as.numeric(test.adultclass)
```

## Alinear características entre conjuntos

```{r}
common_features <- intersect(colnames(train.adultmatrix), colnames(test.adultmatrix))
train.adultmatrix <- train.adultmatrix[, common_features, drop = FALSE]
test.adultmatrix <- test.adultmatrix[, common_features, drop = FALSE]
```

## Convertir a matriz

```{r}
train.adultmatrix <- as.matrix(train.adultmatrix)
test.adultmatrix <- as.matrix(test.adultmatrix)
```

# Análisis exploratorio de datos

## Estructura de datos

```{r}
str(adult)
summary(adult)
```

## Distribución de la variable objetivo

```{r}
prop.table(table(adultclass))
```

## Gráficos para la visualización

### Distribución por edad

```{r}
library(ggplot2)
library(dplyr)

ggplot(data.frame(age = adult$age, target = adultclass), 
       aes(x = age, fill = factor(target))) +
  geom_histogram(bins = 30, alpha = 0.7) +
  labs(title = "Distribución de Edad por Nivel de Ingresos",
       fill = "Ingresos >$50k") +
  scale_fill_discrete(labels = c("No", "Sí"))
```
Conforme se avanza en edad, menor es el ingreso. La franja de edad más común en el estudio es entre 25 y 50.

### Ingresos por nivel educativo

```{r}
adult_analysis <- adult
adult_analysis$target <- adultclass
adult_analysis %>%
  group_by(education) %>%
  summarise(high_income_rate = mean(target == 1), .groups = 'drop') %>%
  ggplot(aes(x = reorder(education, high_income_rate), y = high_income_rate)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Tasa de Ingresos Altos por Nivel Educativo",
       x = "Nivel Educativo",
       y = "Proporción con ingresos >$50k") +
  scale_y_continuous(labels = scales::percent)
```
La educación superior está fuertemente correlacionada con mayor salario. En etapas superiores, el salto salarial es más notable, con excepción de los dos últimos niveles.

# Modelo

```{r,results='hide'}
modelo <- xgboost(data = train.adultmatrix, 
                label = train.adultclass, 
                max.depth = 4, 
                eta = 0.3, 
                nthread = 2, 
                nround = 20, 
                objective = "binary:logistic")
```
- Excelente rendimiento en datos tabulares.
- Manejo automático de valores faltantes.
- Resistente al overfitting.
- Proporciona importancia de variables.

# Predicciones

```{r}
pred_train <- predict(modelo, train.adultmatrix)
pred_test <- predict(modelo, test.adultmatrix)
```

## Convertir probabilidades a clases

```{r}
pred_train_class <- ifelse(pred_train > 0.5, 1, 0)
pred_test_class <- ifelse(pred_test > 0.5, 1, 0)
```

## Evaluar rendimiento

```{r}
train_accuracy <- mean(pred_train_class == train.adultclass)
test_accuracy <- mean(pred_test_class == test.adultclass)
cat("Train Accuracy:", round(train_accuracy, 4), "\n")
cat("Test Accuracy:", round(test_accuracy, 4), "\n")
```

## Matriz de confusión

```{r}
table(pred_test_class,test.adultclass,dnn = c("Predicted class","Actual class"))
```

## Curva ROC

```{r}
library(pROC)
roc_curve <- roc(test.adultclass, pred_test)
plot(roc_curve, main = "Curva ROC")
auc_score <- auc(roc_curve)
text(x = 0.1, y = 0.9, 
     labels = paste("AUC =", round(auc_score, 3)), 
     pos = 4, col = "blue", cex = 1.2)
```
La curva es relativamente buena. El área bajo la curva tiene un valor de 0.881, lo cual es buen indicativo porque al acercarse a 1, discrimina con cierto éxito entre ambas clases.

# Intepretabilidad del modelo

```{r}
importance <- xgb.importance(model = modelo)
xgb.plot.importance(importance, top_n = 10)
print(importance[1:5])
```

- Vemos que el factor más determinante con diferencia a la hora de ganar más o menos de $50,000 es el hecho de estar casado o no.
- Otros motivos que influencian la variable objetivo son los niveles superiores de estudio y la ocupación.

# Conclusiones

- El modelo logra una exactitud satisfactoria para asignar el atributo buscado a cada nuevo individuo, de 82%
- El estado civil es el predictor con más peso para la estimación.
- Como limitación, mencionar que se obvian variables que podrían ser fundamentales como la localización del puesto de trabajo de cada muestra de la tabla. También mencionar el desbalanceo de datos pertenecientes a una clase con respecto a la otra (sólo un 24% ganan más de $50,000).
- De cara al futuro, sería interesante probar otros algoritmos como redes neuronales o árboles de decisión.
